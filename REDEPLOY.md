# Personal AI Knowledge Platform - Complete Redeployment Manual

This guide contains every command and step needed to redeploy the Personal AI Knowledge Platform backend from scratch, based on the complete conversation history and all corrections made during development.

**üöÄ 100% CLI Automated**: This deployment guide requires no AWS Console access. All configuration, deployment, and troubleshooting steps can be completed entirely through the command line using AWS CLI and SAM CLI.

## Prerequisites
- AWS CLI installed and configured
- AWS SAM CLI installed
- Node.js and npm installed
- Python 3.13 installed
- Git repository cloned locally

## Step 1: IAM User + Permissions Setup

### 1.1 Create IAM User for Deployment
```bash
# Create deployment user
aws iam create-user --user-name pai-deployment-user

# Create access key for the user
aws iam create-access-key --user-name pai-deployment-user
```

**Verification:**
```bash
# Verify user was created
aws iam get-user --user-name pai-deployment-user

# List access keys for the user
aws iam list-access-keys --user-name pai-deployment-user
```
**Note:** Save the AccessKeyId and SecretAccessKey from the create-access-key output - you'll need these for step 1.3.  
**Troubleshooting:** If user creation fails, check if a user with this name already exists or if you have IAM permissions.

### 1.2 Create and Attach Policies
```bash
# Create custom policy for deployment
cat > pai-deployment-policy.json << 'EOF_POLICY'
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "cloudformation:*",
                "s3:*",
                "lambda:*",
                "apigateway:*",
                "dynamodb:*",
                "cognito-idp:*",
                "iam:GetRole",
                "iam:CreateRole",
                "iam:AttachRolePolicy",
                "iam:PassRole",
                "secretsmanager:*",
                "logs:*"
            ],
            "Resource": "*"
        }
    ]
}
EOF_POLICY

# Create the policy
aws iam create-policy --policy-name pai-deployment-policy --policy-document file://pai-deployment-policy.json

# Attach policy to user
aws iam attach-user-policy --user-name pai-deployment-user --policy-arn arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):policy/pai-deployment-policy
```

**Verification:**
```bash
# Verify policy was created
aws iam get-policy --policy-arn arn:aws:iam::$(aws sts get-caller-identity --query Account --output text):policy/pai-deployment-policy

# Verify policy is attached to user
aws iam list-attached-user-policies --user-name pai-deployment-user
```
**Troubleshooting:** If policy attachment fails, ensure the policy ARN is correct and the user exists.

### 1.3 Configure AWS CLI with New User
```bash
# Configure AWS CLI with the new access key from step 1.1
aws configure
# Enter the Access Key ID and Secret Access Key from step 1.1
# Set region: ap-south-1
# Set output format: json
```

**Verification:**
```bash
# Verify AWS CLI configuration
aws sts get-caller-identity

# Verify you're using the correct user and region
aws configure list
```
**Expected Output:** The get-caller-identity should show your deployment user ARN.  
**Troubleshooting:** If verification fails, double-check the access keys entered in aws configure.

## Step 2: Create Gemini API Secret in AWS Secrets Manager

```bash
# Create secret for Gemini API key (replace YOUR_GEMINI_API_KEY with actual key)
aws secretsmanager create-secret \
    --name pai-gemini-api-key \
    --description "Gemini API key for PAI platform" \
    --secret-string "YOUR_GEMINI_API_KEY" \
    --region ap-south-1
```

**Verification:**
```bash
# Verify secret was created
aws secretsmanager describe-secret --secret-id pai-gemini-api-key --region ap-south-1

# Test secret retrieval (this will show metadata, not the actual secret value)
aws secretsmanager list-secrets --region ap-south-1 --filters Key="name",Values="pai-gemini-api-key"
```
**Note:** Save the SecretArn from the output - Lambda functions will reference this secret by name.  
**Troubleshooting:** If secret creation fails, ensure the secret name is unique and you have Secrets Manager permissions.

## Step 3: S3 Bucket for PDF Storage

```bash
# Create S3 bucket for PDF storage
aws s3 mb s3://pai-pdf-storage --region ap-south-1

# Enable versioning
# Enable versioning
aws s3api put-bucket-versioning \
    --bucket pai-pdf-storage \
    --versioning-configuration Status=Enabled

# Configure CORS for direct upload from frontend
aws s3api put-bucket-cors \
    --bucket pai-pdf-storage \
    --cors-configuration '{
        "CORSRules": [
            {
                "AllowedHeaders": ["*"],
                "AllowedMethods": ["GET", "POST", "PUT"],
                "AllowedOrigins": ["*"],
                "ExposeHeaders": ["ETag"],
                "MaxAgeSeconds": 3000
            }
        ]
    }'

# Verify CORS configuration
aws s3api get-bucket-cors --bucket pai-pdf-storage
```

**Verification:**
```bash
# Verify bucket was created
aws s3 ls | grep pai-pdf-storage

# Verify bucket versioning is enabled
aws s3api get-bucket-versioning --bucket pai-pdf-storage

# Verify CORS configuration is applied
aws s3api get-bucket-cors --bucket pai-pdf-storage

# Test bucket accessibility
aws s3 ls s3://pai-pdf-storage/
```
**Expected Output:** Bucket should appear in listing, versioning status should be "Enabled", CORS rules should match configuration.  
**Troubleshooting:** If bucket creation fails, the name may not be globally unique. Try adding a random suffix to the bucket name.

## Step 4: DynamoDB Table Creation

```bash
# Create DynamoDB table for embeddings and metadata
aws dynamodb create-table \
    --table-name pai-embeddings-metadata \
    --attribute-definitions AttributeName=doc_id,AttributeType=S \
    --key-schema AttributeName=doc_id,KeyType=HASH \
    --billing-mode PAY_PER_REQUEST \
    --region ap-south-1
```

**Verification:**
```bash
# Verify table was created and is active
aws dynamodb describe-table --table-name pai-embeddings-metadata --region ap-south-1

# List all tables to confirm
aws dynamodb list-tables --region ap-south-1

# Wait for table to become active (if needed)
aws dynamodb wait table-exists --table-name pai-embeddings-metadata --region ap-south-1
```
**Expected Output:** TableStatus should be "ACTIVE" and BillingModeSummary should show "PAY_PER_REQUEST".  
**Note:** The table name "pai-embeddings-metadata" will be used in Lambda environment variables.  
**Troubleshooting:** If table creation fails, check if a table with this name already exists or if you have DynamoDB permissions.

## Step 5: Cognito Setup (Fully Automated with AWS CLI)

### 5.1 Create User Pool
```bash
# Create User Pool with email sign-in and auto-verification
aws cognito-idp create-user-pool \
    --pool-name pai-user-pool \
    --policies '{
        "PasswordPolicy": {
            "MinimumLength": 8,
            "RequireUppercase": false,
            "RequireLowercase": false,
            "RequireNumbers": false,
            "RequireSymbols": false
        }
    }' \
    --auto-verified-attributes email \
    --alias-attributes email \
    --email-configuration '{
        "EmailSendingAccount": "COGNITO_DEFAULT"
    }' \
    --admin-create-user-config '{
        "AllowAdminCreateUserOnly": false
    }' \
    --region ap-south-1

# Save the User Pool ID from the output - you'll need it for the next steps
```

**Verification:**
```bash
# Verify user pool was created
aws cognito-idp list-user-pools --max-results 20 --region ap-south-1

# Get detailed user pool information (replace USER_POOL_ID with actual ID from output)
aws cognito-idp describe-user-pool --user-pool-id USER_POOL_ID --region ap-south-1
```
**Critical:** Copy the "Id" field from the create-user-pool output and save it as USER_POOL_ID for step 5.2.  
**Troubleshooting:** If user pool creation fails, check if email configuration is correct and you have Cognito permissions.

### 5.2 Create App Client
```bash
# Replace USER_POOL_ID with the ID from step 5.1
export USER_POOL_ID="YOUR_USER_POOL_ID_HERE"

# Create App Client without client secret
aws cognito-idp create-user-pool-client \
    --user-pool-id $USER_POOL_ID \
    --client-name pai-client \
    --generate-secret false \
    --explicit-auth-flows ALLOW_USER_PASSWORD_AUTH ALLOW_REFRESH_TOKEN_AUTH \
    --prevent-user-existence-errors ENABLED \
    --region ap-south-1

# Save the Client ID from the output - you'll need it for frontend configuration
```

**Verification:**
```bash
# Verify app client was created (use the USER_POOL_ID from step 5.1)
aws cognito-idp list-user-pool-clients --user-pool-id $USER_POOL_ID --region ap-south-1

# Get detailed client information (replace CLIENT_ID with actual ID from output)
aws cognito-idp describe-user-pool-client \
    --user-pool-id $USER_POOL_ID \
    --client-id CLIENT_ID \
    --region ap-south-1
```
**Critical:** Copy the "ClientId" field from the create-user-pool-client output - this will be used in frontend .env file.  
**Troubleshooting:** If client creation fails, ensure USER_POOL_ID is correct and GenerateSecret is set to false.

### 5.3 Create User Pool Domain
```bash
# Create unique domain prefix using timestamp
export DOMAIN_PREFIX="pai-auth-domain-$(date +%s)"

# Create User Pool Domain
aws cognito-idp create-user-pool-domain \
    --domain $DOMAIN_PREFIX \
    --user-pool-id $USER_POOL_ID \
    --region ap-south-1

echo "Domain created: $DOMAIN_PREFIX"
# Save this domain name for frontend configuration
```

**Verification:**
```bash
# Verify domain was created (use the USER_POOL_ID from step 5.1)
aws cognito-idp describe-user-pool-domain \
    --domain $DOMAIN_PREFIX \
    --region ap-south-1

# List all domains for verification
aws cognito-idp list-user-pool-domains --region ap-south-1
```
**Critical:** The domain prefix ($DOMAIN_PREFIX) will be used in frontend authentication flows.  
**Troubleshooting:** If domain creation fails, the domain name may already be taken. Try a different prefix.

### 5.4 Verify Cognito Setup
```bash
# List all user pools to verify creation
aws cognito-idp list-user-pools --max-results 20 --region ap-south-1

# Get detailed information about your user pool
aws cognito-idp describe-user-pool \
    --user-pool-id $USER_POOL_ID \
    --region ap-south-1

# List app clients for your user pool
aws cognito-idp list-user-pool-clients \
    --user-pool-id $USER_POOL_ID \
    --region ap-south-1

# Get domain information
aws cognito-idp describe-user-pool-domain \
    --domain $DOMAIN_PREFIX \
    --region ap-south-1
```

### 5.5 Get Configuration Values for Frontend
```bash
# Get User Pool ID (if you didn't save it from step 5.1)
aws cognito-idp list-user-pools --max-results 20 \
    --query 'UserPools[?Name==`pai-user-pool`].Id' \
    --output text --region ap-south-1

# Get User Pool Client ID
aws cognito-idp list-user-pool-clients --user-pool-id $USER_POOL_ID \
    --query 'UserPoolClients[0].ClientId' \
    --output text --region ap-south-1

# Get Domain Name
echo "Domain: $DOMAIN_PREFIX"
```

**Important:** Save these three values for Step 9 (Frontend Configuration):
- **User Pool ID**: From step 5.1 output or verification command
- **Client ID**: From step 5.2 output or verification command  
- **Domain**: The domain prefix you created in step 5.3
## Step 6: Lambda Layer Creation

### 6.1 Create FAISS Layer
```bash
# Create layer directory
mkdir -p pai-faiss-layer/python

# Install dependencies
pip install faiss-cpu numpy PyPDF2 requests google-generativeai -t pai-faiss-layer/python/

# Create layer zip
cd pai-faiss-layer
zip -r pai-faiss-layer.zip python/

# Upload to S3
aws s3 cp pai-faiss-layer.zip s3://pai-pdf-storage/pai-faiss-layer.zip --region ap-south-1

# Create Lambda layer
aws lambda publish-layer-version \
    --layer-name pai-faiss-layer \
    --description "FAISS, numpy, PyPDF2, requests, google-generativeai for PAI platform" \
    --content S3Bucket=pai-pdf-storage,S3Key=pai-faiss-layer.zip \
    --compatible-runtimes python3.13 \
    --region ap-south-1

# Note: Save the LayerVersionArn from the output
```

**Verification:**
```bash
# Verify layer was created
aws lambda list-layers --region ap-south-1

# Get specific layer version details
aws lambda get-layer-version \
    --layer-name pai-faiss-layer \
    --version-number 1 \
    --region ap-south-1

# Verify layer was uploaded to S3
aws s3 ls s3://pai-pdf-storage/ | grep pai-faiss-layer.zip
```
**Critical:** Copy the "LayerVersionArn" from the output - this will be referenced in SAM template.  
**Troubleshooting:** If layer creation fails, check if the zip file was uploaded to S3 successfully and has the correct permissions.

## Step 7: Lambda Functions Deployment with AWS SAM

### 7.1 Build SAM Application
```bash
# Navigate to infra directory
cd infra

# Build the SAM application
sam build
```

**Verification:**
```bash
# Verify build completed successfully
ls -la .aws-sam/build/

# Check that all Lambda functions were built
ls -la .aws-sam/build/*/

# Verify template was processed
cat .aws-sam/build/template.yaml | head -20
```
**Troubleshooting:** If build fails, check that template.yaml exists and all Python dependencies are available.

### 7.2 Deploy with SAM
```bash
# Deploy using SAM (first time - guided)
sam deploy --guided

# During guided setup, use these values:
# Stack Name: pai-stack
# AWS Region: ap-south-1
# Confirm changes before deploy: Y
# Allow SAM CLI IAM role creation: Y
# Disable rollback: N
# Save parameters to samconfig.toml: Y

# For subsequent deployments:
sam deploy
```

**Verification:**
```bash
# Verify CloudFormation stack was created
aws cloudformation describe-stacks --stack-name pai-stack --region ap-south-1

# Get stack outputs (API Gateway URL, etc.)
aws cloudformation describe-stacks \
    --stack-name pai-stack \
    --region ap-south-1 \
    --query 'Stacks[0].Outputs'

# Verify Lambda functions were deployed
aws lambda list-functions --region ap-south-1 --query 'Functions[?contains(FunctionName, `pai`)].FunctionName'

# Verify API Gateway was created
aws apigatewayv2 get-apis --region ap-south-1 --query 'Items[?Name==`pai-api`]'
```
**Critical:** Save the API Gateway URL from stack outputs - this will be used in frontend .env file.  
**Troubleshooting:** If deployment fails, check CloudFormation events: `aws cloudformation describe-stack-events --stack-name pai-stack`

**Alternative Manual CloudFormation Deployment:**
```bash
# If SAM deploy fails, use CloudFormation directly
aws cloudformation create-stack \
    --stack-name pai-stack \
    --template-body file://.aws-sam/build/template.yaml \
    --capabilities CAPABILITY_IAM \
    --region ap-south-1
```

## Step 8: API Gateway Configuration (Post-Deployment)

### 8.1 Get API Gateway Information
```bash
# Get API Gateway ID
export API_GATEWAY_ID=$(aws apigatewayv2 get-apis \
    --query 'Items[?Name==`pai-api`].ApiId' \
    --output text --region ap-south-1)

# Get API Gateway URL
export API_GATEWAY_URL=$(aws apigatewayv2 get-apis \
    --query 'Items[?Name==`pai-api`].ApiEndpoint' \
    --output text --region ap-south-1)

# Display the values
echo "API Gateway ID: $API_GATEWAY_ID"
echo "API Gateway URL: $API_GATEWAY_URL"
```

**Verification:**
```bash
# Verify API Gateway exists and is active
aws apigatewayv2 get-api --api-id $API_GATEWAY_ID --region ap-south-1

# List all routes
aws apigatewayv2 get-routes --api-id $API_GATEWAY_ID --region ap-south-1

# Verify API Gateway stage
aws apigatewayv2 get-stages --api-id $API_GATEWAY_ID --region ap-south-1
```
**Critical:** The $API_GATEWAY_URL will be used in frontend .env file and the $API_GATEWAY_ID for CORS configuration.  
**Troubleshooting:** If API Gateway is not found, verify SAM deployment completed successfully.

### 8.2 Test API Endpoints
```bash
# Test upload endpoint (using the API_GATEWAY_URL from step 8.1)
curl -X POST "$API_GATEWAY_URL/upload?filename=test.pdf&auth=test" \
    -H "Content-Type: application/pdf" \
    --data-binary "@path/to/test.pdf"

# Test query endpoint
curl -X POST "$API_GATEWAY_URL/query?auth=test" \
    -H "Content-Type: application/json" \
    -d '{"question": "What is this document about?"}'

# Test presigned URL endpoint
curl -X GET "$API_GATEWAY_URL/presigned-url?filename=test.pdf&auth=test" \
    -H "Content-Type: application/json"
```

**Verification:**
```bash
# Check if endpoints return proper HTTP status codes
curl -I "$API_GATEWAY_URL/upload?filename=test.pdf&auth=test"
curl -I "$API_GATEWAY_URL/query?auth=test"
curl -I "$API_GATEWAY_URL/presigned-url?filename=test.pdf&auth=test"

# Verify Lambda function logs
aws logs describe-log-groups --log-group-name-prefix /aws/lambda/pai --region ap-south-1
```
**Expected:** Endpoints should return 200/400/500 status codes (not 404). 404 means routing is broken.  
**Troubleshooting:** If endpoints return 404, verify API Gateway routes and Lambda function integration.

### 8.3 Configure Lambda Environment Variables
```bash
# Update upload function environment variables
aws lambda update-function-configuration \
    --function-name pai-upload \
    --environment Variables='{
        "S3_BUCKET":"pai-pdf-storage",
        "DYNAMODB_TABLE":"pai-embeddings-metadata",
        "GEMINI_SECRET_NAME":"pai-gemini-api-key"
    }' \
    --region ap-south-1

# Update query function environment variables
aws lambda update-function-configuration \
    --function-name pai-query \
    --environment Variables='{
        "DYNAMODB_TABLE":"pai-embeddings-metadata",
        "GEMINI_SECRET_NAME":"pai-gemini-api-key"
    }' \
    --region ap-south-1

# Update presigned URL function environment variables
aws lambda update-function-configuration \
    --function-name pai-presigned-url \
    --environment Variables='{
        "S3_BUCKET":"pai-pdf-storage"
    }' \
    --region ap-south-1

# Update process upload function environment variables
aws lambda update-function-configuration \
    --function-name pai-process-upload \
    --environment Variables='{
        "DYNAMODB_TABLE":"pai-embeddings-metadata",
        "GEMINI_SECRET_NAME":"pai-gemini-api-key"
    }' \
    --region ap-south-1

# Verify environment variables are set correctly
aws lambda get-function-configuration \
    --function-name pai-upload \
    --region ap-south-1 \
    --query 'Environment.Variables'
```

**Verification:**
```bash
# Verify all Lambda functions have correct environment variables
for func in pai-upload pai-query pai-presigned-url pai-process-upload; do
    echo "=== $func Environment Variables ==="
    aws lambda get-function-configuration \
        --function-name $func \
        --region ap-south-1 \
        --query 'Environment.Variables'
    echo ""
done

# Test that functions can access their resources
aws lambda invoke \
    --function-name pai-upload \
    --region ap-south-1 \
    --payload '{"test": "connectivity"}' \
    /tmp/test-response.json && cat /tmp/test-response.json
```
**Critical:** Verify that:
- pai-upload has S3_BUCKET, DYNAMODB_TABLE, GEMINI_SECRET_NAME
- pai-query has DYNAMODB_TABLE, GEMINI_SECRET_NAME  
- pai-presigned-url has S3_BUCKET
- pai-process-upload has DYNAMODB_TABLE, GEMINI_SECRET_NAME

**Troubleshooting:** If environment variables are missing, re-run the update-function-configuration commands.

## Step 9: Frontend Environment Configuration

### 9.1 Create Frontend Environment File
```bash
# Navigate to frontend directory
cd frontend

# Use the actual values from previous steps
cat > .env << EOF_ENV
REACT_APP_API_URL=$API_GATEWAY_URL
REACT_APP_COGNITO_USER_POOL_ID=$USER_POOL_ID
REACT_APP_COGNITO_USER_POOL_CLIENT_ID=$CLIENT_ID
EOF_ENV

# If you need to manually set values (replace with actual IDs):
# REACT_APP_API_URL=https://your-api-id.execute-api.ap-south-1.amazonaws.com
# REACT_APP_COGNITO_USER_POOL_ID=ap-south-1_your-pool-id
# REACT_APP_COGNITO_USER_POOL_CLIENT_ID=your-client-id
```

**Verification:**
```bash
# Verify .env file was created with correct values
cat .env

# Verify each environment variable is set
echo "API URL: $(grep REACT_APP_API_URL .env)"
echo "User Pool ID: $(grep REACT_APP_COGNITO_USER_POOL_ID .env)"
echo "Client ID: $(grep REACT_APP_COGNITO_USER_POOL_CLIENT_ID .env)"

# Test if the API URL is accessible
curl -I $(grep REACT_APP_API_URL .env | cut -d'=' -f2)
```
**Critical:** Ensure all three environment variables are set correctly:
- API_URL should start with https:// and end with amazonaws.com
- USER_POOL_ID should start with ap-south-1_
- CLIENT_ID should be a string without ap-south-1_ prefix

**Troubleshooting:** If values are incorrect, manually edit the .env file or re-run the cat command with correct values.

### 9.2 Install and Start Frontend
```bash
# Install dependencies
npm install amazon-cognito-identity-js react-router-dom --legacy-peer-deps

# Start development server
npm start
```

**Verification:**
```bash
# Verify dependencies were installed
npm list amazon-cognito-identity-js react-router-dom

# Check if development server starts without errors
# (Run this in a separate terminal)
timeout 10s npm start || echo "Server start check completed"

# Verify frontend is accessible
curl -I http://localhost:3000 || echo "Frontend not yet accessible - this is normal during initial startup"
```
**Expected:** Frontend should be accessible at http://localhost:3000 within 30-60 seconds.  
**Troubleshooting:** If npm install fails, try removing node_modules and package-lock.json, then run npm install again.

## Verification & Testing

### Test DynamoDB Table
```bash
# List tables
aws dynamodb list-tables --region ap-south-1

# Describe table
aws dynamodb describe-table --table-name pai-embeddings-metadata --region ap-south-1
```

### Test S3 Bucket
```bash
# List buckets
aws s3 ls

# List bucket contents
aws s3 ls s3://pai-pdf-storage/
```

### Test Lambda Functions
```bash
# List functions
aws lambda list-functions --region ap-south-1 --query 'Functions[?contains(FunctionName, \`pai\`)].FunctionName'

# Test upload function
aws lambda invoke \
    --function-name pai-upload \
    --region ap-south-1 \
    --payload '{"httpMethod":"POST","queryStringParameters":{"filename":"test.pdf","auth":"test"},"body":"dGVzdCBkYXRh"}' \
    response.json

# Test query function
aws lambda invoke \
    --function-name pai-query \
    --region ap-south-1 \
    --payload '{"httpMethod":"POST","queryStringParameters":{"auth":"test"},"body":"{\"question\":\"test question\"}"}' \
    response.json

# Test presigned URL function
aws lambda invoke \
    --function-name pai-presigned-url \
    --region ap-south-1 \
    --payload '{"httpMethod":"GET","queryStringParameters":{"filename":"test.pdf","auth":"test"}}' \
    response.json

# Test process upload function (S3 event simulation)
aws lambda invoke \
    --function-name pai-process-upload \
    --region ap-south-1 \
    --payload '{"Records":[{"s3":{"bucket":{"name":"pai-pdf-storage"},"object":{"key":"test/test.pdf"}}}]}' \
    response.json
```

### Test API Gateway
```bash
# Get API details
aws apigatewayv2 get-apis --region ap-south-1

# Get routes
aws apigatewayv2 get-routes --api-id YOUR_API_ID --region ap-south-1
```

### Test Cognito
```bash
# List user pools
aws cognito-idp list-user-pools --max-results 20 --region ap-south-1

# Get user pool details
aws cognito-idp describe-user-pool --user-pool-id YOUR_POOL_ID --region ap-south-1

# List user pool clients
aws cognito-idp list-user-pool-clients --user-pool-id YOUR_POOL_ID --region ap-south-1
```

### Test Secrets Manager
```bash
# List secrets
aws secretsmanager list-secrets --region ap-south-1

# Get secret value (will show encrypted)
aws secretsmanager describe-secret --secret-id pai-gemini-api-key --region ap-south-1
```

### Test CloudFormation Stack
```bash
# List stacks
aws cloudformation list-stacks --stack-status-filter CREATE_COMPLETE --region ap-south-1

# Get stack outputs
aws cloudformation describe-stacks \
    --stack-name pai-stack \
    --region ap-south-1 \
    --query 'Stacks[0].Outputs'
```

### Complete System Validation
```bash
# 1. Verify all AWS resources exist
echo "=== Resource Validation ==="
aws s3 ls | grep pai-pdf-storage && echo "‚úÖ S3 Bucket exists" || echo "‚ùå S3 Bucket missing"
aws dynamodb describe-table --table-name pai-embeddings-metadata --region ap-south-1 > /dev/null && echo "‚úÖ DynamoDB Table exists" || echo "‚ùå DynamoDB Table missing"
aws cognito-idp list-user-pools --max-results 20 --region ap-south-1 --query 'UserPools[?Name==`pai-user-pool`].Id' --output text | grep -q "." && echo "‚úÖ Cognito User Pool exists" || echo "‚ùå Cognito User Pool missing"
aws lambda list-functions --region ap-south-1 --query 'Functions[?contains(FunctionName, `pai`)].FunctionName' --output text | wc -w | grep -q "4" && echo "‚úÖ All 4 Lambda functions exist" || echo "‚ùå Some Lambda functions missing"
aws apigatewayv2 get-apis --region ap-south-1 --query 'Items[?Name==`pai-api`].ApiId' --output text | grep -q "." && echo "‚úÖ API Gateway exists" || echo "‚ùå API Gateway missing"

# 2. Test API connectivity
echo -e "\n=== API Connectivity Test ==="
curl -f -s "$API_GATEWAY_URL/presigned-url?filename=test.pdf&auth=test" > /dev/null && echo "‚úÖ API Gateway responding" || echo "‚ùå API Gateway not responding"

# 3. Test Lambda function connectivity
echo -e "\n=== Lambda Function Test ==="
aws lambda invoke --function-name pai-presigned-url --region ap-south-1 --payload '{"httpMethod":"GET","queryStringParameters":{"filename":"test.pdf","auth":"test"}}' /tmp/lambda-test.json > /dev/null && echo "‚úÖ Lambda functions accessible" || echo "‚ùå Lambda functions not accessible"
```

### Frontend Testing Checklist
1. **Frontend Access**: Open http://localhost:3000
   - ‚úÖ Page loads without errors
   - ‚úÖ Cognito authentication form appears
   
2. **User Registration**: Try to register a new user
   - ‚úÖ Registration form submits successfully
   - ‚úÖ Verification email received
   - **Troubleshooting**: If no email received, check Cognito email configuration
   
3. **User Login**: Login with registered user
   - ‚úÖ Login successful after email verification
   - ‚úÖ User dashboard/upload interface appears
   - **Troubleshooting**: If login fails, verify Cognito client configuration has no secret
   
4. **File Upload**: Upload a PDF file
   - ‚úÖ Small files (‚â§2MB): Direct API Gateway upload works
   - ‚úÖ Large files (>2MB): S3 direct upload via presigned URL works
   - ‚úÖ Upload progress indicator appears
   - **Troubleshooting**: If upload fails, check S3 CORS configuration and Lambda logs
   
5. **Document Chat**: Try chatting with uploaded document
   - ‚úÖ Chat interface loads
   - ‚úÖ Questions get responses from the document
   - ‚úÖ Auto-correction system handles document ID mismatches
   - **Troubleshooting**: If chat fails, check DynamoDB table and Gemini API key in Secrets Manager

---

## Troubleshooting Common Issues

### Resource Dependencies Validation
```bash
# Quick validation of all resource dependencies
echo "=== Checking Resource Dependencies ==="

# Check if IAM user has correct permissions
aws iam list-attached-user-policies --user-name pai-deployment-user

# Check if S3 bucket name matches Lambda environment variables
aws lambda get-function-configuration --function-name pai-upload --region ap-south-1 --query 'Environment.Variables.S3_BUCKET'
aws s3 ls | grep pai-pdf-storage

# Check if DynamoDB table name matches Lambda environment variables
aws lambda get-function-configuration --function-name pai-query --region ap-south-1 --query 'Environment.Variables.DYNAMODB_TABLE'
aws dynamodb list-tables --region ap-south-1 | grep pai-embeddings-metadata

# Check if Cognito IDs match frontend configuration
grep REACT_APP_COGNITO_USER_POOL_ID frontend/.env
aws cognito-idp list-user-pools --max-results 20 --region ap-south-1 --query 'UserPools[?Name==`pai-user-pool`].Id'

# Check if API Gateway URL matches frontend configuration
grep REACT_APP_API_URL frontend/.env
aws apigatewayv2 get-apis --region ap-south-1 --query 'Items[?Name==`pai-api`].ApiEndpoint'
```

### Lambda Import Errors
```bash
# Check function logs
aws logs describe-log-groups --log-group-name-prefix /aws/lambda/pai --region ap-south-1

# View recent logs for each function
for func in pai-upload pai-query pai-presigned-url pai-process-upload; do
    echo "=== $func logs ==="
    aws logs tail /aws/lambda/$func --region ap-south-1 --start-time 1h || echo "No recent logs for $func"
done

# Check Lambda layer attachment
aws lambda get-function --function-name pai-upload --region ap-south-1 --query 'Configuration.Layers'
```

### API Gateway CORS Issues
```bash
# Check current CORS configuration
aws apigatewayv2 get-api \
    --api-id YOUR_API_ID \
    --region ap-south-1 \
    --query 'CorsConfiguration'

# Update CORS configuration if needed
aws apigatewayv2 update-api \
    --api-id YOUR_API_ID \
    --cors-configuration AllowOrigins="*",AllowMethods="*",AllowHeaders="*" \
    --region ap-south-1
```

### Cognito Authentication Issues
```bash
# Verify client secret is NOT generated
aws cognito-idp describe-user-pool-client \
    --user-pool-id $USER_POOL_ID \
    --client-id $CLIENT_ID \
    --region ap-south-1 \
    --query 'UserPoolClient.ClientSecret'

# Check email verification configuration
aws cognito-idp describe-user-pool \
    --user-pool-id $USER_POOL_ID \
    --region ap-south-1 \
    --query 'UserPool.AutoVerifiedAttributes'

# Verify domain configuration
aws cognito-idp describe-user-pool-domain \
    --domain $DOMAIN_PREFIX \
    --region ap-south-1 \
    --query 'DomainDescription.Status'

# Test if frontend environment variables match Cognito resources
echo "Frontend USER_POOL_ID: $(grep REACT_APP_COGNITO_USER_POOL_ID frontend/.env | cut -d'=' -f2)"
echo "Actual USER_POOL_ID: $USER_POOL_ID"
echo "Frontend CLIENT_ID: $(grep REACT_APP_COGNITO_USER_POOL_CLIENT_ID frontend/.env | cut -d'=' -f2)"
echo "Actual CLIENT_ID: $CLIENT_ID"
```
**Expected Results:**
- ClientSecret should be null (not generated)
- AutoVerifiedAttributes should include "email"
- Domain status should be "ACTIVE"
- Frontend and actual IDs should match

### DynamoDB Permission Issues
```bash
# Get Lambda execution role
LAMBDA_ROLE=$(aws lambda get-function \
    --function-name pai-query \
    --region ap-south-1 \
    --query 'Configuration.Role' \
    --output text)

echo "Lambda execution role: $LAMBDA_ROLE"

# Check role policies
aws iam list-attached-role-policies \
    --role-name $(echo $LAMBDA_ROLE | cut -d'/' -f2)

# Test DynamoDB access from Lambda
aws lambda invoke \
    --function-name pai-query \
    --region ap-south-1 \
    --payload '{"httpMethod":"POST","queryStringParameters":{"auth":"test"},"body":"{\"question\":\"test\"}"}' \
    /tmp/dynamodb-test.json

cat /tmp/dynamodb-test.json | grep -q "errorMessage" && echo "‚ùå DynamoDB access failed" || echo "‚úÖ DynamoDB access working"

# Verify table permissions
aws dynamodb describe-table \
    --table-name pai-embeddings-metadata \
    --region ap-south-1 \
    --query 'Table.TableStatus'
```

### S3 Upload Issues (Large Files)
```bash
# Check S3 bucket CORS configuration
aws s3api get-bucket-cors --bucket pai-pdf-storage

# Check bucket permissions
aws s3api get-bucket-policy --bucket pai-pdf-storage

# Test bucket accessibility
aws s3 ls s3://pai-pdf-storage/

# Check if presigned URL function is working
aws lambda invoke \
    --function-name pai-presigned-url \
    --region ap-south-1 \
    --payload '{"httpMethod":"GET","queryStringParameters":{"filename":"test.pdf","auth":"test"}}' \
    response.json && cat response.json
```
- The platform now supports S3 direct upload for files larger than 2MB
- API Gateway has a 2MB limit, so presigned URLs are used for larger files

### Doc ID Auto-Correction System
- The system includes auto-correction for doc_id mismatches
- Known mappings are stored in the frontend
- Server-side correction handles unknown mappings

---

## Architecture Updates

### S3 Direct Upload Workflow
The platform now includes an enhanced upload system:

1. **Small files (‚â§2MB)**: Direct API Gateway upload
2. **Large files (>2MB)**: S3 presigned URL workflow
   - Frontend requests presigned URL from \`/presigned-url\` endpoint
   - Direct upload to S3 using presigned URL
   - S3 event triggers processing Lambda function
   - Background processing extracts text and creates embeddings

### Lambda Functions
- \`pai-upload\`: Handles direct uploads via API Gateway
- \`pai-query\`: Processes chat queries with auto-correction
- \`pai-presigned-url\`: Generates S3 presigned URLs for large file uploads
- \`pai-process-upload\`: S3-triggered function for processing uploaded files

---

## Cost Optimization Notes

All resources are configured to use AWS Free Tier where possible:
- DynamoDB: PAY_PER_REQUEST billing mode
- Lambda: Minimal memory and timeout settings
- S3: Standard storage class with lifecycle policies
- API Gateway: HTTP API (cheaper than REST API)

**Estimated Monthly Cost:** $0-5 USD for light usage within free tier limits.

---

## Security Best Practices Implemented

- IAM least privilege access
- Cognito user pool without client secrets
- S3 bucket with proper access policies and CORS
- API Gateway with CORS restrictions
- Lambda functions with minimal required permissions
- Secrets Manager for API keys (not hardcoded)
- S3 presigned URLs with 5-minute expiry for secure uploads

---

## Latest Features

### Doc ID Auto-Correction System
- Client-side known mappings for common doc_id variations
- Server-side correction with DynamoDB fallback
- Visual notifications for corrected queries
- Seamless user experience with automatic fixes

### Enhanced Error Handling
- Comprehensive logging throughout all Lambda functions
- Specific error messages for different failure scenarios
- Auto-retry mechanisms for transient failures
- User-friendly error messages in the frontend

### Large File Support
- S3 direct upload bypasses API Gateway 2MB limit
- Background processing for large PDF files
- Progress indicators for upload status
- Support for files up to 100MB

---

## üìã Critical Values Reference

After successful deployment, save these values for future reference:

```bash
# Create a deployment summary file
cat > deployment-summary.txt << EOF
=== Personal AI Knowledge Platform Deployment Summary ===
Deployment Date: $(date)
AWS Region: ap-south-1

=== Resource Identifiers ===
S3 Bucket: pai-pdf-storage
DynamoDB Table: pai-embeddings-metadata
Secrets Manager Secret: pai-gemini-api-key

=== Cognito Configuration ===
User Pool ID: $USER_POOL_ID
User Pool Client ID: $CLIENT_ID
User Pool Domain: $DOMAIN_PREFIX

=== API Gateway ===
API Gateway ID: $API_GATEWAY_ID
API Gateway URL: $API_GATEWAY_URL

=== Lambda Functions ===
$(aws lambda list-functions --region ap-south-1 --query 'Functions[?contains(FunctionName, `pai`)].FunctionName' --output table)

=== CloudFormation Stack ===
Stack Name: pai-stack
Stack Status: $(aws cloudformation describe-stacks --stack-name pai-stack --region ap-south-1 --query 'Stacks[0].StackStatus' --output text)

=== Environment Variables Validation ===
Frontend .env file contents:
$(cat frontend/.env)
EOF

echo "Deployment summary saved to deployment-summary.txt"
cat deployment-summary.txt
```

## üîß Quick Health Check Command

```bash
# Run this command anytime to check if all resources are healthy
echo "=== PAI Platform Health Check ===" && \
aws s3 ls | grep -q pai-pdf-storage && echo "‚úÖ S3 Bucket: OK" || echo "‚ùå S3 Bucket: FAILED" && \
aws dynamodb describe-table --table-name pai-embeddings-metadata --region ap-south-1 > /dev/null 2>&1 && echo "‚úÖ DynamoDB: OK" || echo "‚ùå DynamoDB: FAILED" && \
aws lambda list-functions --region ap-south-1 --query 'Functions[?contains(FunctionName, `pai`)].FunctionName' --output text | wc -w | grep -q 4 && echo "‚úÖ Lambda Functions: OK (4/4)" || echo "‚ùå Lambda Functions: FAILED" && \
aws apigatewayv2 get-apis --region ap-south-1 --query 'Items[?Name==`pai-api`].ApiId' --output text | grep -q "." && echo "‚úÖ API Gateway: OK" || echo "‚ùå API Gateway: FAILED" && \
curl -f -s "$API_GATEWAY_URL/presigned-url?filename=test.pdf&auth=test" > /dev/null 2>&1 && echo "‚úÖ API Connectivity: OK" || echo "‚ùå API Connectivity: FAILED" && \
echo "=== Health Check Complete ==="
```

This deployment guide ensures a secure, cost-effective, and scalable Personal AI Knowledge Platform deployment with all the latest enhancements, bug fixes, and comprehensive validation checks implemented during development.
